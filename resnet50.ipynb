{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "print(\"cuDNN available:\", torch.backends.cudnn.is_available())\n",
    "print(\"cuDNN version:\", torch.backends.cudnn.version())\n",
    "print(torch.__version__)\n",
    "print(torch.version.cuda)\n",
    "print(torch.backends.cudnn.version())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import gc\n",
    "import sys\n",
    "import time\n",
    "import random\n",
    "import csv\n",
    "import shutil\n",
    "import pathlib\n",
    "import pickle\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from numba import jit, cuda\n",
    "from PIL import Image\n",
    "import cv2\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.optim import AdamW, optim\n",
    "from torchvision import models, transforms\n",
    "import torchvision.transforms.functional as F\n",
    "\n",
    "import timm\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import LightningModule, Trainer\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "\n",
    "from torchmetrics import Metric, F1Score\n",
    "from torch.optim.lr_scheduler import StepLR, ReduceLROnPlateau\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "from tqdm.notebook import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Check for GPU availability\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using {device} for training\")\n",
    "\n",
    "# Path to the images and CSV file\n",
    "img_dir = './data/images'\n",
    "train_file = './data/train_binarized.csv'\n",
    "test_file = './data/test.csv'\n",
    "\n",
    "train_df = pd.read_csv(train_file)\n",
    "test_df = pd.read_csv(test_file, usecols=['ImageID'])\n",
    "train_df\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self,df, img_dir, transform=None):\n",
    "        self.df=df\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.df.iloc[idx,0]\n",
    "        img_path = os.path.join(self.img_dir, img_name)\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        labels = self.df.iloc[idx, 1:19].values.astype('float')\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return img_name,image, labels\n",
    "\n",
    "# Transformations for the images\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(400),  \n",
    "    transforms.RandomCrop(384),  \n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# transform = transforms.Compose([\n",
    "#         transforms.Resize((384, 384)),   \n",
    "#         transforms.RandomHorizontalFlip(), \n",
    "#         transforms.RandomRotation(10),  \n",
    "#         transforms.ToTensor(),  \n",
    "#     ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_set , val_set = train_test_split(train_df,test_size = 0.3)\n",
    "\n",
    "\n",
    "train_dataset = ImageDataset(train_set,img_dir=img_dir, transform=transform)\n",
    "val_dataset = ImageDataset(val_set,img_dir=img_dir, transform=transform)\n",
    "test_dataset = ImageDataset(test_df,img_dir=img_dir, transform=transform)\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset,\n",
    "                                               batch_size = 32,\n",
    "                                               shuffle = True,num_workers=15)\n",
    "val_dataloader = torch.utils.data.DataLoader(val_dataset,\n",
    "                                               batch_size = 32,\n",
    "                                               shuffle = False,num_workers=15)\n",
    "test_dataloader = torch.utils.data.DataLoader(test_dataset,\n",
    "                                               batch_size = 1,\n",
    "                                               shuffle = False,num_workers=15)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "image_name,image, label = train_dataset[0]  \n",
    "\n",
    "image = F.to_pil_image(image)\n",
    "print()\n",
    "# Display the image\n",
    "plt.imshow(image)\n",
    "plt.title(f'Label: {image_name} {label} ')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "timm.list_models(\"resnet*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timm.list_models(\"resnetv2*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# backbone = timm.create_model(\"resnetv2_50\",pretrained=True,num_classes = 0)\n",
    "backbone = timm.create_model(\"resnet50.a1_in1k\",pretrained=True)\n",
    "backbone.reset_classifier(0)  \n",
    "backbone\n",
    "\n",
    "\n",
    "# Model Definition\n",
    "class MLCNNet(nn.Module):\n",
    "    def __init__(self, backbone, n_classes):\n",
    "        super(MLCNNet, self).__init__()\n",
    "        self.model = backbone\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(2048, 256),\n",
    "            nn.BatchNorm1d(256),  \n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),  \n",
    "            nn.Linear(256, n_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "Model = MLCNNet(backbone,18)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class LitMLCNet(pl.LightningModule):\n",
    "    def __init__(self, model):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.f1_score = F1Score(num_labels=18, average='macro', task='multilabel')\n",
    "\n",
    "    def forward(self, x):\n",
    "        print(x.shape)\n",
    "        return self.model(x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        img_name, x, y = batch\n",
    "        logits = self.model(x)\n",
    "        loss = F.binary_cross_entropy_with_logits(logits, y)\n",
    "        # Calculate F1 Score\n",
    "        f1 = self.f1_score(logits.sigmoid(), y.int())\n",
    "        self.log('train_loss', loss, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
    "        self.log('train_f1', f1, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
    "        return {'loss': loss, 'f1': f1}\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        img_name, x, y = batch\n",
    "        logits = self.model(x)\n",
    "        loss = F.binary_cross_entropy_with_logits(logits, y)\n",
    "        f1 = self.f1_score(logits.sigmoid(), y.int())\n",
    "        self.log('val_loss', loss, on_step=False, on_epoch=True, prog_bar=True, logger=True)\n",
    "        self.log('val_f1', f1, on_step=False, on_epoch=True, prog_bar=True, logger=True)\n",
    "        return {'val_loss': loss, 'val_f1': f1}\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.AdamW(self.parameters(), lr=1e-4)\n",
    "        scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=10)\n",
    "        return {\"optimizer\": optimizer, \"lr_scheduler\": scheduler, \"monitor\": \"val_loss\"}\n",
    "\n",
    "    def predict_step(self, batch, batch_idx, dataloader_idx=0):\n",
    "        img_name, x, _ = batch  \n",
    "        preds = self.forward(x)\n",
    "        return preds, img_name\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl_Model = LitMLCNet(Model)\n",
    "trainer = pl.Trainer(\n",
    "    default_root_dir='./',\n",
    "    max_epochs=20,  # Increased epochs\n",
    "    log_every_n_steps=5,\n",
    "    accelerator='gpu',\n",
    "    devices=1,\n",
    "    logger=True\n",
    ")\n",
    "\n",
    "trainer.fit(pl_Model,\n",
    "            train_dataloader,\n",
    "            val_dataloader)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir ./lightning_logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_labels = trainer.predict(pl_Model, dataloaders=test_dataloader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def process_and_save_predictions(preds_labels):\n",
    "    with open('predictions.csv', mode='w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow(['ImageId', 'Labels'])  \n",
    "\n",
    "        for preds, img_names in preds_labels:\n",
    "            for pred, img_name in zip(preds, img_names):\n",
    "                # Convert predictions from one-hot to list of labels\n",
    "                pred = torch.round(torch.sigmoid(pred))  \n",
    "                label_indices = pred.nonzero(as_tuple=True)[0]\n",
    "                labels = ' '.join(str(label_index.item() + 1) for label_index in label_indices)\n",
    "                writer.writerow([img_name, labels])\n",
    "\n",
    "\n",
    "process_and_save_predictions(preds_labels)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

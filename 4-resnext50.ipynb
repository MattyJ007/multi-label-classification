{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "print(\"cuDNN available:\", torch.backends.cudnn.is_available())\n",
    "print(\"cuDNN version:\", torch.backends.cudnn.version())\n",
    "print(torch.__version__)\n",
    "print(torch.version.cuda)\n",
    "print(torch.backends.cudnn.version())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import gc\n",
    "import sys\n",
    "import time\n",
    "import random\n",
    "import csv\n",
    "import shutil\n",
    "import pathlib\n",
    "import pickle\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from numba import jit, cuda\n",
    "from PIL import Image\n",
    "import cv2\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.optim as optim\n",
    "from torch.optim import Adadelta, SGD\n",
    "from torchvision import models, transforms\n",
    "from torch_optimizer import Lamb\n",
    "import timm\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import LightningModule, Trainer\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "\n",
    "from torchmetrics import Metric, F1Score\n",
    "from torch.optim.lr_scheduler import StepLR, ReduceLROnPlateau, CosineAnnealingWarmRestarts\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import json\n",
    "\n",
    "# Global hyperparameters\n",
    "THRESHOLD = 0.5\n",
    "N_LABELS = 18\n",
    "DROPOUT_RATE_1 = 0.5\n",
    "MAX_EPOCHS = 40 \n",
    "BATCH_SIZE = 64\n",
    "RESIZE_DIM = 224\n",
    "TEST_SPLIT_SIZE = 0.3\n",
    "RANDOM_HORIZONTAL_FLIP_PROB = 0.5\n",
    "RANDOM_VERTICAL_FLIP_PROB = 0.5\n",
    "COLOR_JITTER_BRIGHTNESS = 0.2\n",
    "COLOR_JITTER_CONTRAST = 0.2\n",
    "COLOR_JITTER_SATURATION = 0.2\n",
    "COLOR_JITTER_HUE = 0.1\n",
    "RANDOM_ROTATION_DEGREES = 30\n",
    "RANDOM_AFFINE_DEGREES = 0\n",
    "RANDOM_AFFINE_TRANSLATE = (0.1, 0.1)\n",
    "RANDOM_AFFINE_SCALE = (0.9, 1.1)\n",
    "RANDOM_PERSPECTIVE_DISTORTION_SCALE = 0.2\n",
    "RANDOM_PERSPECTIVE_PROB = 0.5\n",
    "RANDOM_GRAYSCALE_PROB = 0.1\n",
    "NORMALIZE_MEAN = [0.485, 0.456, 0.406]\n",
    "NORMALIZE_STD = [0.229, 0.224, 0.225]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for GPU availability\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using {device} for training\")\n",
    "\n",
    "# Path to the images and CSV file\n",
    "img_dir = './data/images'\n",
    "train_file = './data/train_binarized.csv'\n",
    "test_file = './data/test.csv'\n",
    "\n",
    "train_df = pd.read_csv(train_file)\n",
    "test_df = pd.read_csv(test_file, usecols=['ImageID'])\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageDataset(Dataset):\n",
    "    def __init__(self,df, img_dir, transform=None):\n",
    "        self.df=df\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.df.iloc[idx,0]\n",
    "        img_path = os.path.join(self.img_dir, img_name)\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        labels = self.df.iloc[idx, 1:19].values.astype('float')\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return img_name,image, labels\n",
    "\n",
    "# Transformations for the images\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((RESIZE_DIM, RESIZE_DIM)),  # Resize to 224x224\n",
    "    transforms.RandomHorizontalFlip(p=RANDOM_HORIZONTAL_FLIP_PROB),  # Randomly flip horizontally\n",
    "    transforms.RandomVerticalFlip(p=RANDOM_VERTICAL_FLIP_PROB),  # 50% chance of flipping vertically\n",
    "    transforms.ColorJitter(brightness=COLOR_JITTER_BRIGHTNESS, contrast=COLOR_JITTER_CONTRAST, saturation=COLOR_JITTER_SATURATION, hue=COLOR_JITTER_HUE),  # Randomly change the brightness, contrast, saturation and hue\n",
    "    transforms.RandomRotation(RANDOM_ROTATION_DEGREES),  # Randomly rotate the image by up to 30 degrees\n",
    "    transforms.RandomAffine(degrees=RANDOM_AFFINE_DEGREES, translate=RANDOM_AFFINE_TRANSLATE, scale=RANDOM_AFFINE_SCALE),  # Random affine transformations with translation and scaling\n",
    "    transforms.RandomPerspective(distortion_scale=RANDOM_PERSPECTIVE_DISTORTION_SCALE, p=RANDOM_PERSPECTIVE_PROB),  # Random perspective transformation with a 50% chance\n",
    "    transforms.RandomGrayscale(p=RANDOM_GRAYSCALE_PROB),  # Randomly convert image to grayscale with a 10% chance\n",
    "    transforms.ToTensor(),  # Convert image to tensor\n",
    "    transforms.Normalize(mean=NORMALIZE_MEAN, std=NORMALIZE_STD)  # Normalize the tensor with mean and std for pre-trained models\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize((RESIZE_DIM, RESIZE_DIM)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=NORMALIZE_MEAN, std=NORMALIZE_STD)  # Normalization parameters for pre-trained models\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_set , val_set = train_test_split(train_df,test_size = TEST_SPLIT_SIZE)\n",
    "\n",
    "train_dataset = ImageDataset(train_set,img_dir=img_dir, transform=transform)\n",
    "val_dataset = ImageDataset(val_set,img_dir=img_dir, transform=transform)\n",
    "test_dataset = ImageDataset(test_df,img_dir=img_dir, transform=test_transform)\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset,\n",
    "                                               batch_size = BATCH_SIZE,\n",
    "                                               shuffle = True,num_workers=5)\n",
    "val_dataloader = torch.utils.data.DataLoader(val_dataset,\n",
    "                                               batch_size = BATCH_SIZE,\n",
    "                                               shuffle = False,num_workers=5)\n",
    "test_dataloader = torch.utils.data.DataLoader(test_dataset,\n",
    "                                               batch_size = BATCH_SIZE,\n",
    "                                               shuffle = False,num_workers=5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms.functional as F\n",
    "\n",
    "image_name,image, label = train_dataset[0]  \n",
    "\n",
    "image = F.to_pil_image(image)\n",
    "print()\n",
    "# Display the image\n",
    "plt.imshow(image)\n",
    "plt.title(f'Label: {image_name} {label} ')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Backbone definition using ResNeXt50_32x4d\n",
    "backbone = timm.create_model('resnext50_32x4d.a1h_in1k', pretrained=True)\n",
    "\n",
    "backbone.reset_classifier(0)  \n",
    "\n",
    "class MLCNNet(nn.Module):\n",
    "    def __init__(self, backbone, n_classes):\n",
    "        super(MLCNNet, self).__init__()\n",
    "        self.model = backbone\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(2048, 512),\n",
    "            nn.BatchNorm1d(512),  \n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(DROPOUT_RATE_1),  \n",
    "            nn.Linear(512, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(DROPOUT_RATE_1),  \n",
    "            nn.Linear(256, n_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "model = MLCNNet(backbone, N_LABELS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "from torchmetrics.classification import MultilabelF1Score\n",
    "\n",
    "class LitMLCNet(pl.LightningModule):\n",
    "    def __init__(self, model):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.f1_score = MultilabelF1Score(num_labels=N_LABELS, average='macro')\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        img_name, x, y = batch\n",
    "        logits = self.model(x)\n",
    "        loss = F.binary_cross_entropy_with_logits(logits, y)\n",
    "        f1 = self.f1_score(logits.sigmoid(), y.int())\n",
    "        self.log('train_loss', loss, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
    "        self.log('train_f1', f1, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
    "        return {'loss': loss, 'f1': f1}\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        img_name, x, y = batch\n",
    "        logits = self.model(x)\n",
    "        loss = F.binary_cross_entropy_with_logits(logits, y)\n",
    "        f1 = self.f1_score(logits.sigmoid(), y.int())\n",
    "        self.log('val_loss', loss, on_step=False, on_epoch=True, prog_bar=True, logger=True)\n",
    "        self.log('val_f1', f1, on_step=False, on_epoch=True, prog_bar=True, logger=True)\n",
    "        return {'val_loss': loss, 'val_f1': f1}\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = Lamb(self.parameters(), lr=0.001)\n",
    "        scheduler = CosineAnnealingWarmRestarts(optimizer, T_0=10, T_mult=1, eta_min=0)\n",
    "        return {\"optimizer\": optimizer, \"lr_scheduler\": scheduler, \"monitor\": \"val_f1\"}\n",
    "\n",
    "    def predict_step(self, batch, batch_idx, dataloader_idx=0):\n",
    "        img_name, x, _ = batch  \n",
    "        preds = self.forward(x)\n",
    "        return preds, img_name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl_Model = LitMLCNet(model)\n",
    "\n",
    "torch.set_float32_matmul_precision('high')\n",
    "\n",
    "weights_path = './FINAL_MODEL/FINAL_RESNEXT.pth'\n",
    "pl_Model.load_state_dict(torch.load(weights_path),strict=False)\n",
    "\n",
    "trainer = pl.Trainer()\n",
    "\n",
    "# Uncomment if training model \n",
    "\n",
    "# trainer = pl.Trainer(\n",
    "#     default_root_dir='./',\n",
    "#     max_epochs=40,  # Increased epochs\n",
    "#     log_every_n_steps=10,\n",
    "#     accelerator='gpu',\n",
    "#     devices=1,\n",
    "#     logger=True\n",
    "# )\n",
    "\n",
    "# trainer.fit(pl_Model,\n",
    "#             train_dataloader,\n",
    "#             val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir ./lightning_logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_labels = trainer.predict(pl_Model, dataloaders=test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of possible labels\n",
    "possible_labels = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13, 14, 15, 16, 17, 18, 19]\n",
    "\n",
    "# Convert predictions to label format\n",
    "def get_labels_from_logits(logits, threshold=THRESHOLD):\n",
    "    return [str(possible_labels[i]) for i in range(len(logits)) if logits[i] >= threshold]\n",
    "\n",
    "# Prepare the data for CSV\n",
    "csv_data = []\n",
    "for preds, img_name in preds_labels:\n",
    "    preds = preds.sigmoid().cpu().numpy()\n",
    "    img_name = img_name[0]  # Assuming img_name is a single-element list\n",
    "    labels_str = \" \".join(get_labels_from_logits(preds[0]))\n",
    "    csv_data.append([img_name, labels_str])\n",
    "\n",
    "# Write to CSV\n",
    "csv_file = './FINAL_MODEL/510369965-490424191-490299418-ResNext-Predictions.csv'\n",
    "with open(csv_file, mode='w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(['ImageID', 'Labels'])\n",
    "    writer.writerows(csv_data)\n",
    "\n",
    "print(f\"Predictions saved to {csv_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Raw JSON predictions for ensemble\n",
    "predictions = []\n",
    "for preds, img_names in preds_labels:\n",
    "        for pred, img_name in zip(preds, img_names):\n",
    "          predictions.append(torch.sigmoid(pred))\n",
    "\n",
    "predictions = [tensor.tolist() for tensor in predictions]\n",
    "\n",
    "with open('./processed-data/rawPredictions-resnet.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(predictions, f, ensure_ascii=False, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

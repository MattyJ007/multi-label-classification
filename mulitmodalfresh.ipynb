{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "prXBrNW6nTX6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\eoinp\\anaconda3\\envs\\deepl\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import models, transforms\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "import pdb\n",
        "from sklearn.model_selection import train_test_split\n",
        "from PIL import Image\n",
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
        "from torch.nn.utils import clip_grad_norm_, clip_grad_value_\n",
        "\n",
        "import warnings\n",
        "import datetime\n",
        "\n",
        "# Suppress the FutureWarning\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning, message=\".*Series.__getitem__ treating keys as positions is deprecated.*\")\n",
        "\n",
        "# Custom Dataset\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, df, transform=None, base_img_path=\"./data/images/\"):\n",
        "        self.df=df\n",
        "        self.transform = transform\n",
        "        self.base_img_path=base_img_path\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image_path = self.base_img_path + self.df.iloc[idx][1]\n",
        "        caption = self.df.iloc[idx][8]\n",
        "        label = self.df.iloc[idx][6]\n",
        "\n",
        "        image = Image.open(image_path).convert('RGB')\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        #image is already tensor cutesey of transform sequence\n",
        "        return image, torch.tensor(caption), torch.tensor(label, dtype=torch.float32)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Model definition\n",
        "class MultiModalModel(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_size, hidden_dim, num_classes=18, lstm_layers=1, bidirectional=True):\n",
        "        super(MultiModalModel, self).__init__()\n",
        "\n",
        "        self.resnet = models.resnet34(pretrained=True)\n",
        "        self.resnet_output_dim = self.resnet.fc.in_features\n",
        "        self.resnet.fc = nn.Identity()\n",
        "\n",
        "        self.embedding_dim = embed_size\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.num_layers = lstm_layers\n",
        "        self.bidirectional = bidirectional\n",
        "\n",
        "        self.embedding = nn.Embedding(num_embeddings=vocab_size, embedding_dim=self.embedding_dim, padding_idx=0)\n",
        "        self.lstm = nn.LSTM(input_size=self.embedding_dim, hidden_size=self.hidden_dim, num_layers=self.num_layers,\n",
        "                            batch_first=True, bidirectional=self.bidirectional)\n",
        "\n",
        "        lstm_output_dim = self.hidden_dim * 2 if self.bidirectional else self.hidden_dim\n",
        "        classifier_input_dim = self.resnet_output_dim + lstm_output_dim\n",
        "        self.resnet_classifier = nn.Sequential(\n",
        "            nn.BatchNorm1d(self.resnet_output_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(self.resnet_output_dim, num_classes)\n",
        "        )\n",
        "        self.lstm_classifier = nn.Sequential(\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(lstm_output_dim, num_classes),\n",
        "        )\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(num_classes * 2, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, images, captions):\n",
        "        image_features = self.resnet(images)\n",
        "        embedded = self.embedding(captions)\n",
        "        lstm_out, _ = self.lstm(embedded)\n",
        "\n",
        "        if self.bidirectional:\n",
        "            lstm_out = torch.cat((lstm_out[:, -1, :self.hidden_dim], lstm_out[:, 0, self.hidden_dim:]), dim=1)\n",
        "        else:\n",
        "            lstm_out = lstm_out[:, -1, :]\n",
        "\n",
        "        resnet_classifier_output = self.resnet_classifier(image_features)\n",
        "        lstm_classifier_output = self.lstm_classifier(lstm_out)\n",
        "\n",
        "        combined_features = torch.cat((resnet_classifier_output, lstm_classifier_output), dim=1)\n",
        "        # combined_features = torch.cat((image_features, lstm_out), dim=1)\n",
        "        output = self.classifier(combined_features)\n",
        "\n",
        "        return output\n",
        "\n",
        "# Training function\n",
        "def train_epoch(model, train_loader, val_loader, num_epochs, criterion, optimizer, scheduler, device, log_file, clip_effect=10, model_path=\"./models/\", history_path=\"./history/\", save_prefix=\"second_clasification_head_\"):\n",
        "    best_val_acc = 0.0\n",
        "    history = {\n",
        "        'epoch': [],\n",
        "        'train_loss': [],\n",
        "        'val_loss': [],\n",
        "        'val_accuracy': [],\n",
        "        'val_f1_score': []\n",
        "    }\n",
        "    count_epoch = 0\n",
        "    # Train the model\n",
        "    for epoch in tqdm(range(num_epochs), position=0, leave=True):\n",
        "        count_epoch += 1\n",
        "        model.train()\n",
        "        train_loss = 0.0\n",
        "        for images, captions, labels in train_loader:\n",
        "            images, captions, labels = images.to(device), captions.to(device), labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images, captions)\n",
        "            loss = criterion(outputs, labels.float())\n",
        "            loss.backward()\n",
        "\n",
        "            clip_grad_value_(model.parameters(), clip_effect)\n",
        "\n",
        "            optimizer.step()\n",
        "\n",
        "            train_loss += loss.item() * images.size(0)\n",
        "\n",
        "        # scheduler.step()\n",
        "        train_loss /= len(train_loader.dataset)\n",
        "\n",
        "        model.eval()\n",
        "        val_loss = 0.0\n",
        "        all_labels = []\n",
        "        all_outputs = []\n",
        "        with torch.no_grad():\n",
        "            for images, captions, labels in tqdm(val_loader, position=0, leave=True):\n",
        "                images, captions, labels = images.to(device), captions.to(device), labels.to(device)\n",
        "\n",
        "                outputs = model(images, captions)\n",
        "                loss = criterion(outputs, labels.float())\n",
        "                val_loss += loss.item() * images.size(0)\n",
        "\n",
        "                all_labels.append(labels.cpu().numpy())\n",
        "                probabilities = (torch.sigmoid(outputs).cpu().numpy()  > 0.5).astype(int)\n",
        "\n",
        "                # assert(x > 0 for x in probabilities[1:])\n",
        "                all_outputs.append(probabilities)\n",
        "\n",
        "        val_loss /= len(val_loader.dataset)\n",
        "\n",
        "        scheduler.step(val_loss)\n",
        "        all_labels = np.concatenate(all_labels, axis=0)\n",
        "        all_outputs = np.concatenate(all_outputs, axis=0)\n",
        "        val_accuracy = accuracy_score(all_labels, all_outputs)\n",
        "        val_f1 = f1_score(all_labels, all_outputs, average='micro')\n",
        "\n",
        "        history['epoch'].append(epoch + 1)\n",
        "        history['train_loss'].append(train_loss)\n",
        "        history['val_loss'].append(val_loss)\n",
        "        history['val_accuracy'].append(val_accuracy)\n",
        "        history['val_f1_score'].append(val_f1)\n",
        "\n",
        "        print(f'Epoch [{epoch + 1}/{num_epochs}], Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy:.4f}, Val F1 Score: {val_f1:.4f}')\n",
        "\n",
        "        if (val_accuracy > best_val_acc and best_val_acc > 0.50) or count_epoch % 20 == 0:\n",
        "            best_val_acc = val_accuracy\n",
        "            torch.save(model.state_dict(), model_path + save_prefix + '_vacc{}_vf1{}_vlss{}_epoch{}.pth'.format(int(val_accuracy *100), int(val_f1*100), int(val_loss*100), count_epoch))\n",
        "            \n",
        "\n",
        "        time_stamp = datetime.datetime.now()\n",
        "        pd.DataFrame(history).to_csv(history_path + save_prefix + \"_{}vacc{}_epoch{}.csv\".format(time_stamp.strftime(\"%d_%m_%y_%H_%M\"), int(val_accuracy*100), count_epoch), index=False)\n",
        "\n",
        "# Example usage\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(10),\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "H2AUgWVzqZ0E"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\eoinp\\anaconda3\\envs\\deepl\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:558: UserWarning: This DataLoader will create 12 worker processes in total. Our suggested max number of worker in current system is 8 (`cpuset` is not taken into account), which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        }
      ],
      "source": [
        "train = pd.read_csv('./processed-data/train.csv', converters={'EncodedLabels': pd.eval, 'TokensWithPadding': pd.eval})\n",
        "# train = train[:1024]\n",
        "train_df, val_df = train_test_split(train, test_size=0.1, random_state=42)\n",
        "\n",
        "train_set = CustomDataset(train_df, transform)\n",
        "val_set = CustomDataset(val_df, transform)\n",
        "trainloader = DataLoader(train_set, batch_size=64, shuffle=True, num_workers=12)\n",
        "valloader = DataLoader(val_set, batch_size=64, shuffle=True, num_workers=12)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tpB9pGbmqXdY",
        "outputId": "c6613aac-708f-4821-80fa-d465d4691587"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/adnlp-server/anaconda3/envs/eoinenvpy11/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/home/adnlp-server/anaconda3/envs/eoinenvpy11/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet34_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet34_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "100%|███████████████████████████████████████████| 47/47 [00:03<00:00, 14.59it/s]\n",
            "  1%|▌                                         | 1/70 [00:57<1:06:41, 58.00s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/70], Train Loss: 0.2940, Val Loss: 0.1816, Val Accuracy: 0.4530, Val F1 Score: 0.5975\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|███████████████████████████████████████████| 47/47 [00:03<00:00, 14.36it/s]\n",
            "  3%|█▏                                        | 2/70 [01:56<1:06:05, 58.32s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [2/70], Train Loss: 0.1999, Val Loss: 0.1758, Val Accuracy: 0.4530, Val F1 Score: 0.5975\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|███████████████████████████████████████████| 47/47 [00:03<00:00, 14.98it/s]\n",
            "  4%|█▊                                        | 3/70 [02:55<1:05:11, 58.39s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [3/70], Train Loss: 0.1912, Val Loss: 0.1685, Val Accuracy: 0.4530, Val F1 Score: 0.5975\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|███████████████████████████████████████████| 47/47 [00:03<00:00, 14.82it/s]\n",
            "  6%|██▍                                       | 4/70 [03:53<1:04:22, 58.52s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [4/70], Train Loss: 0.1815, Val Loss: 0.1592, Val Accuracy: 0.4527, Val F1 Score: 0.6128\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|███████████████████████████████████████████| 47/47 [00:03<00:00, 14.53it/s]\n",
            "  7%|███                                       | 5/70 [04:52<1:03:27, 58.58s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [5/70], Train Loss: 0.1721, Val Loss: 0.1508, Val Accuracy: 0.4490, Val F1 Score: 0.6244\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|███████████████████████████████████████████| 47/47 [00:03<00:00, 14.63it/s]\n",
            "  9%|███▌                                      | 6/70 [05:51<1:02:31, 58.62s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [6/70], Train Loss: 0.1647, Val Loss: 0.1427, Val Accuracy: 0.4550, Val F1 Score: 0.6315\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|███████████████████████████████████████████| 47/47 [00:03<00:00, 14.38it/s]\n",
            " 10%|████▏                                     | 7/70 [06:50<1:01:39, 58.73s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [7/70], Train Loss: 0.1585, Val Loss: 0.1384, Val Accuracy: 0.4780, Val F1 Score: 0.6493\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|███████████████████████████████████████████| 47/47 [00:03<00:00, 14.90it/s]\n",
            " 11%|████▊                                     | 8/70 [07:48<1:00:38, 58.69s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [8/70], Train Loss: 0.1537, Val Loss: 0.1364, Val Accuracy: 0.4803, Val F1 Score: 0.6571\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|███████████████████████████████████████████| 47/47 [00:03<00:00, 15.17it/s]\n",
            " 13%|█████▋                                      | 9/70 [08:47<59:36, 58.63s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [9/70], Train Loss: 0.1491, Val Loss: 0.1336, Val Accuracy: 0.4870, Val F1 Score: 0.6622\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|███████████████████████████████████████████| 47/47 [00:03<00:00, 14.96it/s]\n",
            " 14%|██████▏                                    | 10/70 [09:45<58:37, 58.62s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [10/70], Train Loss: 0.1461, Val Loss: 0.1305, Val Accuracy: 0.4907, Val F1 Score: 0.6724\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|███████████████████████████████████████████| 47/47 [00:03<00:00, 14.52it/s]\n",
            " 16%|██████▊                                    | 11/70 [10:44<57:39, 58.63s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [11/70], Train Loss: 0.1430, Val Loss: 0.1304, Val Accuracy: 0.4897, Val F1 Score: 0.6731\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|███████████████████████████████████████████| 47/47 [00:03<00:00, 14.47it/s]\n",
            " 17%|███████▎                                   | 12/70 [11:43<56:43, 58.69s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [12/70], Train Loss: 0.1396, Val Loss: 0.1325, Val Accuracy: 0.4993, Val F1 Score: 0.6779\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|███████████████████████████████████████████| 47/47 [00:03<00:00, 14.68it/s]\n",
            " 19%|███████▉                                   | 13/70 [12:41<55:46, 58.70s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [13/70], Train Loss: 0.1365, Val Loss: 0.1277, Val Accuracy: 0.5010, Val F1 Score: 0.6816\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|███████████████████████████████████████████| 47/47 [00:03<00:00, 14.86it/s]\n",
            " 20%|████████▌                                  | 14/70 [13:40<54:46, 58.69s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [14/70], Train Loss: 0.1341, Val Loss: 0.1296, Val Accuracy: 0.5083, Val F1 Score: 0.6875\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|███████████████████████████████████████████| 47/47 [00:03<00:00, 14.44it/s]\n",
            " 21%|█████████▏                                 | 15/70 [14:39<53:49, 58.72s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [15/70], Train Loss: 0.1316, Val Loss: 0.1281, Val Accuracy: 0.5057, Val F1 Score: 0.6867\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|███████████████████████████████████████████| 47/47 [00:03<00:00, 15.22it/s]\n",
            " 23%|█████████▊                                 | 16/70 [15:37<52:47, 58.66s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [16/70], Train Loss: 0.1295, Val Loss: 0.1271, Val Accuracy: 0.5110, Val F1 Score: 0.6953\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|███████████████████████████████████████████| 47/47 [00:03<00:00, 14.61it/s]\n",
            " 24%|██████████▍                                | 17/70 [16:36<51:50, 58.70s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [17/70], Train Loss: 0.1272, Val Loss: 0.1261, Val Accuracy: 0.5090, Val F1 Score: 0.6922\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "vocab_size = 7330\n",
        "embed_size = 28\n",
        "hidden_dim = 256\n",
        "num_classes = 18\n",
        "num_epochs = 70\n",
        "log_file = 'training_log.csv'\n",
        "lr = 0.1\n",
        "\n",
        "model = MultiModalModel(vocab_size, embed_size, hidden_dim, num_classes)\n",
        "\n",
        "# model.load_state_dict(torch.load(\"./multimodalmodels/multimodalmodel_resnet_34_clipped_val0_5_two_class_heads_noclip_oldhead_vacc62_vf180_vlss9_epoch20.pth\"))\n",
        "model.to(device)\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = optimizer = optim.Adadelta(model.parameters(), lr=lr)#Adam(model.parameters(), lr=lr)\n",
        "optimizer.param_groups[0]['initial_lr'] = lr\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=2, threshold=0.01, threshold_mode='rel', cooldown=0, min_lr=0, eps=1e-08)\n",
        "\n",
        "train_epoch(model, trainloader, valloader, num_epochs, criterion, optimizer, scheduler, device, log_file)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}

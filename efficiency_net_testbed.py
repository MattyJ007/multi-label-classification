# -*- coding: utf-8 -*-
"""efficiency_net_testbed.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1mewfMDlLbq9nbzs340_Bgl3iFuUy85Mw
"""

import re
from io import StringIO
import torch
from torch.utils.data import Dataset, DataLoader
from transformers import YolosForObjectDetection, YolosFeatureExtractor
import pandas as pd
import matplotlib.pyplot as plt
from PIL import Image
import os
import pdb
from sklearn.model_selection import train_test_split

def read_df(filepath):
  with open(filepath) as file:
    lines = [re.sub(r'([^,])"(\s*[^\n])', r'\1/"\2', line) for line in file]
    df = pd.read_csv(StringIO(''.join(lines)), escapechar="/")
  return df

DATA_BASE_PATH = ".//data/images/"#/content/drive/MyDrive/DeepLA2/images/"
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')


# Load data
train_df = read_df("./data/" + 'train.csv')#[:1122]

for idx, row in train_df.iterrows():
  new_row = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
  temp = row["Labels"].split(" ")
  for i in temp:
    new_row[int(i) - 1] = 1
  row["Labels"] = new_row

train_df, val_df = train_test_split(train_df, test_size=0.1, random_state=42)
train_df

import os
import pandas as pd
from PIL import Image
import torch
from torch.utils.data import Dataset, DataLoader
from torchvision import transforms

class CustomDataset(Dataset):
    def __init__(self, dataframe, transform=None):
        self.dataframe = dataframe
        self.transform = transform

    def __len__(self):
        return len(self.dataframe)

    def __getitem__(self, idx):
        img_path = self.dataframe.iloc[idx, 0]  # Assuming image paths are in the first column
        image = Image.open(DATA_BASE_PATH + img_path).convert('RGB')
        label_list = self.dataframe.iloc[idx, 1:2]

        label = torch.tensor(label_list, dtype=torch.float32)  # Assuming labels start from the second column

        if self.transform:
            image = self.transform(image)

        return image, label

# Define transformations
transform = transforms.Compose([
    transforms.Resize((380, 380)),  # EfficientNet-B4 expects 380x380 inputs
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
])

# Create datasets
train_dataset = CustomDataset(train_df, transform=transform)
test_dataset = CustomDataset(val_df, transform=transform)

# Create data loaders
train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)
test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)

from transformers import AutoModelForImageClassification, TrainingArguments, Trainer

model = AutoModelForImageClassification.from_pretrained("google/efficientnet-b4", num_labels=19, ignore_mismatched_sizes=True
)

# Replace the classifier head for multi-label classification
model.classifier = torch.nn.Linear(model.classifier.in_features, 19)
model.classifier_out = torch.nn.Sigmoid()

from transformers import AdamW
from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score
import numpy as np
# Define the optimizer
optimizer = AdamW(model.parameters(), lr=1e-7)

# Define loss function for multi-label classification
loss_fn = torch.nn.BCEWithLogitsLoss()

# def train_epoch(model, data_loader, loss_fn, optimizer, device):
#     model.train()
#     losses = []
#     for images, labels in tqdm(data_loader, position=0, leave=True):
#         images, labels = images.to(device), labels.to(device)
#         labels = labels.squeeze(1)
#         outputs = model(images).logits
#         loss = loss_fn(outputs, labels)
#         optimizer.zero_grad()
#         loss.backward()
#         optimizer.step()
#         losses.append(loss.item())
#     return sum(losses) / len(losses)

# def evaluate(model, data_loader, loss_fn, device):
#     model.eval()
#     losses = []
#     with torch.no_grad():
#         for images, labels in tqdm(data_loader, position=0, leave=True):
#             images, labels = images.to(device), labels.to(device)
#             labels = labels.squeeze(1)
#             outputs = model(images).logits
#             loss = loss_fn(outputs, labels)
#             losses.append(loss.item())
#     return sum(losses) / len(losses)

def train_epoch(model, data_loader, loss_fn, optimizer, device):
    model.train()
    losses = []
    total_preds, total_labels = [], []
    for images, labels in tqdm(data_loader, position=0, leave=True):
        images, labels = images.to(device), labels.to(device)
        labels = labels.squeeze(1)
        outputs = model(images).logits
        loss = loss_fn(outputs, labels)
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()
        losses.append(loss.item())

        # Applying threshold to predictions
        preds = outputs > 0.5
        total_preds.append(preds.cpu().numpy())
        total_labels.append(labels.cpu().numpy())

    train_loss = sum(losses) / len(losses)
    total_preds = np.vstack(total_preds)
    total_labels = np.vstack(total_labels)
    precision = precision_score(total_labels, total_preds, average='samples')
    recall = recall_score(total_labels, total_preds, average='samples')
    f1 = f1_score(total_labels, total_preds, average='samples')
    accuracy = accuracy_score(total_labels, total_preds)

    return train_loss, precision, recall, f1, accuracy

def evaluate(model, data_loader, loss_fn, device):
  model.eval()
  losses = []
  total_preds, total_labels = [], []
  with torch.no_grad():
      for images, labels in tqdm(data_loader, position=0, leave=True):
          images, labels = images.to(device), labels.to(device)
          labels = labels.squeeze(1)
          outputs = model(images).logits
          loss = loss_fn(outputs, labels)
          losses.append(loss.item())

          preds = outputs > 0.5
          total_preds.append(preds.cpu().numpy())
          total_labels.append(labels.cpu().numpy())

  val_loss = sum(losses) / len(losses)
  total_preds = np.vstack(total_preds)
  total_labels = np.vstack(total_labels)
  precision = precision_score(total_labels, total_preds, average='samples')
  recall = recall_score(total_labels, total_preds, average='samples')
  f1 = f1_score(total_labels, total_preds, average='samples')
  accuracy = accuracy_score(total_labels, total_preds)

  return val_loss, precision, recall, f1, accuracy

# Device configuration
import datetime
from tqdm import tqdm
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model.to(device)
# Training loop
num_epochs = 10
last_val_loss = 100.0
val_accuracy = 0.0
with open('training_metrics.txt', 'w') as f:
    for epoch in tqdm(range(num_epochs), desc="Training Epochs"):
        train_loss, train_precision, train_recall, train_f1, train_accuracy = train_epoch(model, train_loader, loss_fn, optimizer, device)
        val_loss, val_precision, val_recall, val_f1, val_accuracy = evaluate(model, test_loader, loss_fn, device)

        # Log to terminal
        print(f'\nEpoch {epoch+1}, Train Loss: {train_loss}, Train Precision: {train_precision}, Train Recall: {train_recall}, Train F1: {train_f1}, Train Accuracy: {train_accuracy}')
        print(f'Epoch {epoch+1}, Validation Loss: {val_loss}, Val Precision: {val_precision}, Val Recall: {val_recall}, Val F1: {val_f1}, Val Accuracy: {val_accuracy}')

        # Append to file
        f.write(f'{datetime.datetime.now()}, Epoch {epoch+1}, Train Loss: {train_loss}, Train Precision: {train_precision}, Train Recall: {train_recall}, Train F1: {train_f1}, Train Accuracy: {train_accuracy}\n')
        f.write(f'{datetime.datetime.now()}, Epoch {epoch+1}, Validation Loss: {val_loss}, Val Precision: {val_precision}, Val Recall: {val_recall}, Val F1: {val_f1}, Val Accuracy: {val_accuracy}\n')
        if epoch % 5 == 0 and (val_loss < last_val_loss or val_accuracy > val_accuracy):
          model.save_pretrained("./multi-label-classification/pretrained_checkpoint_epoch_{}".format(epoch))

# # Define the transformation
# transform = transforms.Compose([
#     transforms.Resize((380, 380)),  # Resize to the input size expected by EfficientNet-B4
#     transforms.ToTensor(),
#     transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),  # Normalization
# ])

# # Function to load and preprocess the image
# def preprocess_image(image_path):
#     image = Image.open(image_path).convert('RGB')
#     image = transform(image)
#     image = image.unsqueeze(0)  # Add batch dimension
#     return image

# # Function to predict
# def predict(image_path, model):
#     model.to(torch.device('cpu'))
#     image_tensor = preprocess_image(image_path)
#     with torch.no_grad():  # Ensure no gradients are calculated
#         outputs = model(image_tensor).logits
#         predictions = torch.sigmoid(outputs)  # Apply sigmoid to get probabilities
#         predictions = predictions > 0.001  # Threshold the probabilities to get binary labels
#     return predictions

# Usage
# image_path = DATA_BASE_PATH + '6.jpg'
# predictions = predict(image_path, model)
# print(predictions)

import torch, gc
gc.collect()
torch.cuda.empty_cache()


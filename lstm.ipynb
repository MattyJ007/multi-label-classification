{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon May 13 17:59:55 2024       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 550.54.10              Driver Version: 551.61         CUDA Version: 12.4     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce RTX 3060 ...    On  |   00000000:01:00.0 Off |                  N/A |\n",
      "| N/A   48C    P8              9W /   64W |     358MiB /   6144MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A      1081      C   /python3.11                                 N/A      |\n",
      "+-----------------------------------------------------------------------------------------+\n",
      "NVIDIA GeForce RTX 3060 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(torch.cuda.get_device_name(0))\n",
    "# ^ Comment out if cpu :)\n",
    "\n",
    "import json\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>ImageID</th>\n",
       "      <th>Labels</th>\n",
       "      <th>Caption</th>\n",
       "      <th>Tokens</th>\n",
       "      <th>LabelIds</th>\n",
       "      <th>EncodedLabels</th>\n",
       "      <th>DictionaryIds</th>\n",
       "      <th>TokensWithPadding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.jpg</td>\n",
       "      <td>[1]</td>\n",
       "      <td>Woman in swim suit holding parasol on sunny day.</td>\n",
       "      <td>['woman', 'swim', 'suit', 'holding', 'parasol'...</td>\n",
       "      <td>[0]</td>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[7236, 6376, 6297, 3077, 4457, 6316, 1714]</td>\n",
       "      <td>[7236, 6376, 6297, 3077, 4457, 6316, 1714, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.jpg</td>\n",
       "      <td>[1, 19]</td>\n",
       "      <td>A couple of men riding horses on top of a gree...</td>\n",
       "      <td>['couple', 'men', 'riding', 'horses', 'top', '...</td>\n",
       "      <td>[0, 17]</td>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[1524, 3891, 5237, 3117, 6650, 2827, 2351]</td>\n",
       "      <td>[1524, 3891, 5237, 3117, 6650, 2827, 2351, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2.jpg</td>\n",
       "      <td>[1]</td>\n",
       "      <td>They are brave for riding in the jungle on tho...</td>\n",
       "      <td>['brave', 'riding', 'jungle', 'eleph']</td>\n",
       "      <td>[0]</td>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[754, 5237, 3368, 2093]</td>\n",
       "      <td>[754, 5237, 3368, 2093, 0, 0, 0, 0, 0, 0, 0, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3.jpg</td>\n",
       "      <td>[8, 3, 13]</td>\n",
       "      <td>a black and silver clock tower at an intersect...</td>\n",
       "      <td>['black', 'silver', 'clock', 'tower', 'interse...</td>\n",
       "      <td>[7, 2, 11]</td>\n",
       "      <td>[0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, ...</td>\n",
       "      <td>[616, 5718, 1257, 6684, 3267, 4138, 6738]</td>\n",
       "      <td>[616, 5718, 1257, 6684, 3267, 4138, 6738, 0, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4.jpg</td>\n",
       "      <td>[8, 3, 7]</td>\n",
       "      <td>A train coming to a stop on the tracks out side.</td>\n",
       "      <td>['train', 'coming', 'stop', 'tracks', 'sid']</td>\n",
       "      <td>[7, 2, 6]</td>\n",
       "      <td>[0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, ...</td>\n",
       "      <td>[6704, 1367, 6178, 6694, 5677]</td>\n",
       "      <td>[6704, 1367, 6178, 6694, 5677, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 ImageID      Labels  \\\n",
       "0           0   0.jpg         [1]   \n",
       "1           1   1.jpg     [1, 19]   \n",
       "2           2   2.jpg         [1]   \n",
       "3           3   3.jpg  [8, 3, 13]   \n",
       "4           4   4.jpg   [8, 3, 7]   \n",
       "\n",
       "                                             Caption  \\\n",
       "0   Woman in swim suit holding parasol on sunny day.   \n",
       "1  A couple of men riding horses on top of a gree...   \n",
       "2  They are brave for riding in the jungle on tho...   \n",
       "3  a black and silver clock tower at an intersect...   \n",
       "4   A train coming to a stop on the tracks out side.   \n",
       "\n",
       "                                              Tokens    LabelIds  \\\n",
       "0  ['woman', 'swim', 'suit', 'holding', 'parasol'...         [0]   \n",
       "1  ['couple', 'men', 'riding', 'horses', 'top', '...     [0, 17]   \n",
       "2             ['brave', 'riding', 'jungle', 'eleph']         [0]   \n",
       "3  ['black', 'silver', 'clock', 'tower', 'interse...  [7, 2, 11]   \n",
       "4       ['train', 'coming', 'stop', 'tracks', 'sid']   [7, 2, 6]   \n",
       "\n",
       "                                       EncodedLabels  \\\n",
       "0  [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "1  [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "2  [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "3  [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, ...   \n",
       "4  [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, ...   \n",
       "\n",
       "                                DictionaryIds  \\\n",
       "0  [7236, 6376, 6297, 3077, 4457, 6316, 1714]   \n",
       "1  [1524, 3891, 5237, 3117, 6650, 2827, 2351]   \n",
       "2                     [754, 5237, 3368, 2093]   \n",
       "3   [616, 5718, 1257, 6684, 3267, 4138, 6738]   \n",
       "4              [6704, 1367, 6178, 6694, 5677]   \n",
       "\n",
       "                                   TokensWithPadding  \n",
       "0  [7236, 6376, 6297, 3077, 4457, 6316, 1714, 0, ...  \n",
       "1  [1524, 3891, 5237, 3117, 6650, 2827, 2351, 0, ...  \n",
       "2  [754, 5237, 3368, 2093, 0, 0, 0, 0, 0, 0, 0, 0...  \n",
       "3  [616, 5718, 1257, 6684, 3267, 4138, 6738, 0, 0...  \n",
       "4  [6704, 1367, 6178, 6694, 5677, 0, 0, 0, 0, 0, ...  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The numpy arrays seem to have been converted to strings when saved to csv. We need to convert them back into lists\n",
    "\n",
    "train = pd.read_csv('./processed-data/train.csv', converters={'EncodedLabels': pd.eval, 'TokensWithPadding': pd.eval})\n",
    "train.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "# Mismatched storage :(\n",
    "print(type(train['EncodedLabels']))\n",
    "print(type(train['EncodedLabels'][0]))\n",
    "print(type(train['TokensWithPadding']))\n",
    "print(type(train['TokensWithPadding'][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make type consistent and convert to tensor\n",
    "def dataframeColumnToTensor(column):\n",
    "  array = []\n",
    "  for row in column:\n",
    "    array.append(row.tolist())\n",
    "  return torch.tensor(array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "trainingTokens = dataframeColumnToTensor(train['TokensWithPadding'])\n",
    "trainingEncodedLabels = dataframeColumnToTensor(train['EncodedLabels'])\n",
    "# Sanity check for tensors\n",
    "print(type(trainingTokens))\n",
    "print(type(trainingTokens[0]))\n",
    "print(type(trainingEncodedLabels))\n",
    "print(type(trainingEncodedLabels[0]))\n",
    "print(type(trainingEncodedLabels[0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([25496, 28])\n",
      "torch.Size([4500, 28])\n",
      "torch.Size([25496, 18])\n",
      "torch.Size([4500, 18])\n"
     ]
    }
   ],
   "source": [
    "# Split out validation set\n",
    "xTrain, xVal, yTrain, yVal = train_test_split(\n",
    "  trainingTokens,\n",
    "  trainingEncodedLabels,\n",
    "  test_size=0.15,\n",
    "  random_state=7\n",
    ")\n",
    "\n",
    "# Tokens\n",
    "print(xTrain.shape)\n",
    "print(xVal.shape)\n",
    "# Labels\n",
    "print(yTrain.shape)\n",
    "print(yVal.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Hyperparameter\n",
    "BATCH_SIZE=128\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "trainData = TensorDataset(xTrain, yTrain)\n",
    "testData = TensorDataset(xVal, yVal)\n",
    "\n",
    "trainLoader = DataLoader(dataset=trainData, batch_size=BATCH_SIZE, shuffle=True)\n",
    "testLoader = DataLoader(dataset=testData, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./processed-data/dictionary.json') as f:\n",
    "    dictionary = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class LSTMClassifier(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, dictionary_size, num_labels, dropout_prob, bidirectional):\n",
    "        super(LSTMClassifier, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.dictionary_size = dictionary_size\n",
    "        self.num_labels = num_labels\n",
    "        self.dropout_prob = dropout_prob\n",
    "        self.bidirectional = bidirectional\n",
    "\n",
    "        self.word_embeddings = nn.Embedding(dictionary_size, input_size)\n",
    "\n",
    "        # two lstms? num_layers=2\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, batch_first=True, bidirectional=bidirectional)\n",
    "\n",
    "        # Linear layer for each label\n",
    "        self.classifiers = nn.ModuleList([\n",
    "            nn.Sequential(\n",
    "                nn.Dropout(p=dropout_prob),\n",
    "                nn.Linear(in_features=hidden_size * (2 if bidirectional else 1), out_features=1)\n",
    "            ) for _ in range(num_labels)\n",
    "        ])\n",
    "\n",
    "    def forward(self, sentences):\n",
    "        # Create the word embeddings\n",
    "        embeds = self.word_embeddings(sentences)\n",
    "\n",
    "        # Pass it through the LSTM\n",
    "        lstm_out, _ = self.lstm(embeds)\n",
    "\n",
    "        # Get the last time step output for each label\n",
    "        if self.bidirectional:\n",
    "            lstm_out = torch.cat((lstm_out[:, -1, :self.hidden_size], lstm_out[:, 0, self.hidden_size:]), dim=1)\n",
    "        else:\n",
    "            lstm_out = lstm_out[:, -1, :]\n",
    "        \n",
    "        # Calculate the predictions for each label\n",
    "        outputs = {f'label{i+1}': torch.sigmoid(self.classifiers[i](lstm_out)).squeeze() for i in range(self.num_labels)}\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "INPUT_SIZE = 128\n",
    "HIDDEN_SIZE = 256\n",
    "DICTIONARY_SIZE = len(dictionary)\n",
    "LEARNING_RATE=0.001\n",
    "NUM_LABELS=18\n",
    "DROPOUT_RATE=0.4\n",
    "BIDIRECTIONAL=False\n",
    "\n",
    "# Initialize model, loss function, and optimizer\n",
    "model = LSTMClassifier(INPUT_SIZE, HIDDEN_SIZE, DICTIONARY_SIZE, NUM_LABELS, DROPOUT_RATE, BIDIRECTIONAL).to(device)\n",
    "\n",
    "model = LSTMClassifier(INPUT_SIZE, HIDDEN_SIZE, DICTIONARY_SIZE).to(device)\n",
    "\n",
    "# Load previous model for continued training\n",
    "# Caveat - the model structure can't be changed else the weight dimensions won't match\n",
    "# model.load_state_dict(torch.load('./models/lstm.pt'))\n",
    "# model.eval()\n",
    "\n",
    "loss_function = nn.CrossEntropyLoss().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed: 0.4 mins\n",
      "Epoch: 1, Training loss: 882.5585, Training accuracy: 56.79%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[83], line 57\u001b[0m\n\u001b[1;32m     54\u001b[0m startTime \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[0;32m---> 57\u001b[0m     loss, correct, total \u001b[38;5;241m=\u001b[39m training_epoch(model, optimizer, loss_function, trainLoader)\n\u001b[1;32m     59\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m epoch \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m5\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m epoch \u001b[38;5;241m==\u001b[39m epochs \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m     60\u001b[0m             \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTime elapsed: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m(time\u001b[38;5;241m.\u001b[39mtime()\u001b[38;5;250m \u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;250m \u001b[39mstartTime)\u001b[38;5;250m \u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m60\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.1f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m mins\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[83], line 47\u001b[0m, in \u001b[0;36mtraining_epoch\u001b[0;34m(model, optimizer, loss_function, data_loader)\u001b[0m\n\u001b[1;32m     44\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     45\u001b[0m     epoch_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;241m*\u001b[39m batch_size\n\u001b[0;32m---> 47\u001b[0m     combined_predictions \u001b[38;5;241m=\u001b[39m combine_and_threshold_predictions(class_predictions)\n\u001b[1;32m     49\u001b[0m     correct_predictions \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m accuracy_score(combined_predictions\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy(), targets\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy())\u001b[38;5;241m*\u001b[39mbatch_size\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m epoch_loss, correct_predictions, total_examples\n",
      "Cell \u001b[0;32mIn[83], line 17\u001b[0m, in \u001b[0;36mcombine_and_threshold_predictions\u001b[0;34m(class_predictions)\u001b[0m\n\u001b[1;32m     15\u001b[0m all_entries \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(combined_tensor\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]):\n\u001b[0;32m---> 17\u001b[0m     l \u001b[38;5;241m=\u001b[39m combined_tensor[i]\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(l, \u001b[38;5;28mfloat\u001b[39m):\n\u001b[1;32m     19\u001b[0m         l \u001b[38;5;241m=\u001b[39m [l, class_predictions[key][i]\u001b[38;5;241m.\u001b[39mitem()]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def calculate_loss(loss_func, outputs, targets):\n",
    "    total_loss = 0\n",
    "    for idx, key in enumerate(outputs):\n",
    "        output = outputs[key].to(device).double()\n",
    "        target = targets[:, idx].to(device).double()\n",
    "        total_loss += loss_func(output, target)\n",
    "    return total_loss\n",
    "\n",
    "def combine_and_threshold_predictions(class_predictions):\n",
    "    combined_tensor = None\n",
    "    for i, key in enumerate(class_predictions.keys()):\n",
    "        if i == 0:\n",
    "            combined_tensor = class_predictions[key]\n",
    "        else:\n",
    "            all_entries = []\n",
    "            for i in range(combined_tensor.shape[0]):\n",
    "                l = combined_tensor[i].tolist()\n",
    "                if isinstance(l, float):\n",
    "                    l = [l, class_predictions[key][i].item()]\n",
    "                else:\n",
    "                    l.append(class_predictions[key][i].item())\n",
    "                all_entries.append(l)\n",
    "            combined_tensor = torch.tensor(all_entries)\n",
    "    return combined_tensor.detach().apply_(lambda x: int(x > 0.5))\n",
    "\n",
    "def training_epoch(model, optimizer, loss_function, data_loader):\n",
    "    epoch_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "    total_examples = 0\n",
    "\n",
    "    for tokens, targets in data_loader:\n",
    "        tokens = tokens.to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        batch_size = tokens.shape[0]\n",
    "        total_examples += batch_size\n",
    "\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        class_predictions = model(tokens)\n",
    "        loss = calculate_loss(loss_function, class_predictions, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item() * batch_size\n",
    "\n",
    "        combined_predictions = combine_and_threshold_predictions(class_predictions)\n",
    "\n",
    "        correct_predictions += accuracy_score(combined_predictions.cpu().numpy(), targets.cpu().numpy())*batch_size\n",
    "    return epoch_loss, correct_predictions, total_examples\n",
    "\n",
    "epochs = 20\n",
    "\n",
    "startTime = time.time()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    loss, correct, total = training_epoch(model, optimizer, loss_function, trainLoader)\n",
    "        \n",
    "    if epoch % 5 == 0 or epoch == epochs - 1:\n",
    "            print(f'Time elapsed: {(time.time() - startTime) / 60:.1f} mins')\n",
    "            print(f'Epoch: {epoch + 1}, Training loss: {loss / total:.4f}, Training accuracy: {correct / total * 100:.2f}%')\n",
    "\n",
    "print(f'Total Training Time: {(time.time() - startTime) / 60:.4f} mins')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model size: 5.105MB\n"
     ]
    }
   ],
   "source": [
    "param_size = 0\n",
    "for param in model.parameters():\n",
    "    param_size += param.nelement() * param.element_size()\n",
    "buffer_size = 0\n",
    "for buffer in model.buffers():\n",
    "    buffer_size += buffer.nelement() * buffer.element_size()\n",
    "\n",
    "size_all_mb = (param_size + buffer_size) / 1024**2\n",
    "print('model size: {:.3f}MB'.format(size_all_mb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), './models/lstm.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

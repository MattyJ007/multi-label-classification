{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NVIDIA GeForce RTX 3060 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(torch.cuda.get_device_name(0))\n",
    "# ^ Comment out if cpu :)\n",
    "\n",
    "import json\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import time\n",
    "import csv\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>ImageID</th>\n",
       "      <th>Labels</th>\n",
       "      <th>Caption</th>\n",
       "      <th>Tokens</th>\n",
       "      <th>LabelIds</th>\n",
       "      <th>EncodedLabels</th>\n",
       "      <th>DictionaryIds</th>\n",
       "      <th>TokensWithPadding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.jpg</td>\n",
       "      <td>[1]</td>\n",
       "      <td>Woman in swim suit holding parasol on sunny day.</td>\n",
       "      <td>['woman', 'swim', 'suit', 'holding', 'parasol'...</td>\n",
       "      <td>[0]</td>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[7236, 6376, 6297, 3077, 4457, 6316, 1714]</td>\n",
       "      <td>[7236, 6376, 6297, 3077, 4457, 6316, 1714, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.jpg</td>\n",
       "      <td>[1, 19]</td>\n",
       "      <td>A couple of men riding horses on top of a gree...</td>\n",
       "      <td>['couple', 'men', 'riding', 'horses', 'top', '...</td>\n",
       "      <td>[0, 17]</td>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[1524, 3891, 5237, 3117, 6650, 2827, 2351]</td>\n",
       "      <td>[1524, 3891, 5237, 3117, 6650, 2827, 2351, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2.jpg</td>\n",
       "      <td>[1]</td>\n",
       "      <td>They are brave for riding in the jungle on tho...</td>\n",
       "      <td>['brave', 'riding', 'jungle', 'eleph']</td>\n",
       "      <td>[0]</td>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[754, 5237, 3368, 2093]</td>\n",
       "      <td>[754, 5237, 3368, 2093, 0, 0, 0, 0, 0, 0, 0, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3.jpg</td>\n",
       "      <td>[8, 3, 13]</td>\n",
       "      <td>a black and silver clock tower at an intersect...</td>\n",
       "      <td>['black', 'silver', 'clock', 'tower', 'interse...</td>\n",
       "      <td>[7, 2, 11]</td>\n",
       "      <td>[0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, ...</td>\n",
       "      <td>[616, 5718, 1257, 6684, 3267, 4138, 6738]</td>\n",
       "      <td>[616, 5718, 1257, 6684, 3267, 4138, 6738, 0, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4.jpg</td>\n",
       "      <td>[8, 3, 7]</td>\n",
       "      <td>A train coming to a stop on the tracks out side.</td>\n",
       "      <td>['train', 'coming', 'stop', 'tracks', 'sid']</td>\n",
       "      <td>[7, 2, 6]</td>\n",
       "      <td>[0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, ...</td>\n",
       "      <td>[6704, 1367, 6178, 6694, 5677]</td>\n",
       "      <td>[6704, 1367, 6178, 6694, 5677, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 ImageID      Labels  \\\n",
       "0           0   0.jpg         [1]   \n",
       "1           1   1.jpg     [1, 19]   \n",
       "2           2   2.jpg         [1]   \n",
       "3           3   3.jpg  [8, 3, 13]   \n",
       "4           4   4.jpg   [8, 3, 7]   \n",
       "\n",
       "                                             Caption  \\\n",
       "0   Woman in swim suit holding parasol on sunny day.   \n",
       "1  A couple of men riding horses on top of a gree...   \n",
       "2  They are brave for riding in the jungle on tho...   \n",
       "3  a black and silver clock tower at an intersect...   \n",
       "4   A train coming to a stop on the tracks out side.   \n",
       "\n",
       "                                              Tokens    LabelIds  \\\n",
       "0  ['woman', 'swim', 'suit', 'holding', 'parasol'...         [0]   \n",
       "1  ['couple', 'men', 'riding', 'horses', 'top', '...     [0, 17]   \n",
       "2             ['brave', 'riding', 'jungle', 'eleph']         [0]   \n",
       "3  ['black', 'silver', 'clock', 'tower', 'interse...  [7, 2, 11]   \n",
       "4       ['train', 'coming', 'stop', 'tracks', 'sid']   [7, 2, 6]   \n",
       "\n",
       "                                       EncodedLabels  \\\n",
       "0  [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "1  [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "2  [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "3  [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, ...   \n",
       "4  [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, ...   \n",
       "\n",
       "                                DictionaryIds  \\\n",
       "0  [7236, 6376, 6297, 3077, 4457, 6316, 1714]   \n",
       "1  [1524, 3891, 5237, 3117, 6650, 2827, 2351]   \n",
       "2                     [754, 5237, 3368, 2093]   \n",
       "3   [616, 5718, 1257, 6684, 3267, 4138, 6738]   \n",
       "4              [6704, 1367, 6178, 6694, 5677]   \n",
       "\n",
       "                                   TokensWithPadding  \n",
       "0  [7236, 6376, 6297, 3077, 4457, 6316, 1714, 0, ...  \n",
       "1  [1524, 3891, 5237, 3117, 6650, 2827, 2351, 0, ...  \n",
       "2  [754, 5237, 3368, 2093, 0, 0, 0, 0, 0, 0, 0, 0...  \n",
       "3  [616, 5718, 1257, 6684, 3267, 4138, 6738, 0, 0...  \n",
       "4  [6704, 1367, 6178, 6694, 5677, 0, 0, 0, 0, 0, ...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The numpy arrays seem to have been converted to strings when saved to csv. We need to convert them back into lists\n",
    "\n",
    "train = pd.read_csv('./processed-data/train.csv', converters={'EncodedLabels': pd.eval, 'TokensWithPadding': pd.eval})\n",
    "train.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "# Mismatched storage :(\n",
    "print(type(train['EncodedLabels']))\n",
    "print(type(train['EncodedLabels'][0]))\n",
    "print(type(train['TokensWithPadding']))\n",
    "print(type(train['TokensWithPadding'][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make type consistent and convert to tensor\n",
    "def dataframeColumnToTensor(column):\n",
    "  array = []\n",
    "  for row in column:\n",
    "    array.append(row.tolist())\n",
    "  return torch.tensor(array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "trainingTokens = dataframeColumnToTensor(train['TokensWithPadding'])\n",
    "trainingEncodedLabels = dataframeColumnToTensor(train['EncodedLabels'])\n",
    "# Sanity check for tensors\n",
    "print(type(trainingTokens))\n",
    "print(type(trainingTokens[0]))\n",
    "print(type(trainingEncodedLabels))\n",
    "print(type(trainingEncodedLabels[0]))\n",
    "print(type(trainingEncodedLabels[0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([25496, 28])\n",
      "torch.Size([4500, 28])\n",
      "torch.Size([25496, 18])\n",
      "torch.Size([4500, 18])\n"
     ]
    }
   ],
   "source": [
    "# Split out validation set\n",
    "xTrain, xVal, yTrain, yVal = train_test_split(\n",
    "  trainingTokens,\n",
    "  trainingEncodedLabels,\n",
    "  test_size=0.15,\n",
    "  random_state=7\n",
    ")\n",
    "\n",
    "# Tokens\n",
    "print(xTrain.shape)\n",
    "print(xVal.shape)\n",
    "# Labels\n",
    "print(yTrain.shape)\n",
    "print(yVal.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Hyperparameter\n",
    "BATCH_SIZE=128\n",
    "\n",
    "trainData = TensorDataset(xTrain, yTrain)\n",
    "validationData = TensorDataset(xVal, yVal)\n",
    "\n",
    "trainLoader = DataLoader(dataset=trainData, batch_size=BATCH_SIZE, shuffle=True)\n",
    "# TODO Not used\n",
    "validationLoader = DataLoader(dataset=validationData, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./processed-data/dictionary.json') as f:\n",
    "    dictionary = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class LSTMClassifier(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, dictionary_size, num_labels, dropout_prob, bidirectional):\n",
    "        super(LSTMClassifier, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.dictionary_size = dictionary_size\n",
    "        self.num_labels = num_labels\n",
    "        self.dropout_prob = dropout_prob\n",
    "        self.bidirectional = bidirectional\n",
    "\n",
    "        self.word_embeddings = nn.Embedding(dictionary_size, input_size)\n",
    "\n",
    "        # two lstms? num_layers=2\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, batch_first=True, bidirectional=bidirectional)\n",
    "\n",
    "        # Linear layer for each label\n",
    "        self.classifiers = nn.ModuleList([\n",
    "            nn.Sequential(\n",
    "                nn.Dropout(p=dropout_prob),\n",
    "                nn.Linear(in_features=hidden_size * (2 if bidirectional else 1), out_features=1)\n",
    "            ) for _ in range(num_labels)\n",
    "        ])\n",
    "\n",
    "    def forward(self, sentences):\n",
    "        # Create the word embeddings\n",
    "        embeds = self.word_embeddings(sentences)\n",
    "\n",
    "        # Pass it through the LSTM\n",
    "        lstm_out, _ = self.lstm(embeds)\n",
    "\n",
    "        # Get the last time step output for each label\n",
    "        if self.bidirectional:\n",
    "            lstm_out = torch.cat((lstm_out[:, -1, :self.hidden_size], lstm_out[:, 0, self.hidden_size:]), dim=1)\n",
    "        else:\n",
    "            lstm_out = lstm_out[:, -1, :]\n",
    "        \n",
    "        # Calculate the predictions for each label\n",
    "        outputs = {f'label{i+1}': torch.sigmoid(self.classifiers[i](lstm_out)).squeeze() for i in range(self.num_labels)}\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "INPUT_SIZE = 128\n",
    "HIDDEN_SIZE = 256\n",
    "DICTIONARY_SIZE = len(dictionary)\n",
    "LEARNING_RATE=0.001\n",
    "NUM_LABELS=18\n",
    "DROPOUT_RATE=0.4\n",
    "BIDIRECTIONAL=False\n",
    "\n",
    "# Initialize model, loss function, and optimizer\n",
    "model = LSTMClassifier(INPUT_SIZE, HIDDEN_SIZE, DICTIONARY_SIZE, NUM_LABELS, DROPOUT_RATE, BIDIRECTIONAL).to(device)\n",
    "\n",
    "# Load previous model for continued training\n",
    "# Caveat - the model structure can't be changed else the weight dimensions won't match\n",
    "model.load_state_dict(torch.load('./models/lstm_56per_40e_1lstmL_40drop.pt'))\n",
    "model.eval()\n",
    "\n",
    "loss_function = nn.CrossEntropyLoss().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed: 0.0 mins\n",
      "Epoch: 1, Training loss: 876.7906, Training accuracy: 71.64%\n",
      "Time elapsed: 0.2 mins\n",
      "Epoch: 6, Training loss: 877.0947, Training accuracy: 71.36%\n",
      "Time elapsed: 0.4 mins\n",
      "Epoch: 11, Training loss: 877.1617, Training accuracy: 71.26%\n",
      "Time elapsed: 0.6 mins\n",
      "Epoch: 16, Training loss: 877.0010, Training accuracy: 69.81%\n",
      "Time elapsed: 0.8 mins\n",
      "Epoch: 21, Training loss: 877.0779, Training accuracy: 71.06%\n",
      "Time elapsed: 1.0 mins\n",
      "Epoch: 26, Training loss: 876.7980, Training accuracy: 71.67%\n",
      "Time elapsed: 1.2 mins\n",
      "Epoch: 31, Training loss: 877.0522, Training accuracy: 71.62%\n",
      "Time elapsed: 1.5 mins\n",
      "Epoch: 36, Training loss: 877.2152, Training accuracy: 71.09%\n",
      "Time elapsed: 1.7 mins\n",
      "Epoch: 41, Training loss: 877.1738, Training accuracy: 71.22%\n",
      "Time elapsed: 2.0 mins\n",
      "Epoch: 46, Training loss: 877.0395, Training accuracy: 72.42%\n",
      "Time elapsed: 2.2 mins\n",
      "Epoch: 51, Training loss: 876.7566, Training accuracy: 72.69%\n",
      "Time elapsed: 2.4 mins\n",
      "Epoch: 56, Training loss: 876.5930, Training accuracy: 71.69%\n",
      "Time elapsed: 2.6 mins\n",
      "Epoch: 61, Training loss: 876.9069, Training accuracy: 71.05%\n",
      "Time elapsed: 2.8 mins\n",
      "Epoch: 66, Training loss: 876.8906, Training accuracy: 71.91%\n",
      "Time elapsed: 3.0 mins\n",
      "Epoch: 71, Training loss: 876.3640, Training accuracy: 73.44%\n",
      "Time elapsed: 3.2 mins\n",
      "Epoch: 76, Training loss: 876.1153, Training accuracy: 72.79%\n",
      "Time elapsed: 3.4 mins\n",
      "Epoch: 81, Training loss: 877.0468, Training accuracy: 67.89%\n",
      "Time elapsed: 3.6 mins\n",
      "Epoch: 86, Training loss: 876.3013, Training accuracy: 73.01%\n",
      "Time elapsed: 3.8 mins\n",
      "Epoch: 91, Training loss: 875.9740, Training accuracy: 73.24%\n",
      "Time elapsed: 4.0 mins\n",
      "Epoch: 96, Training loss: 876.1297, Training accuracy: 73.18%\n",
      "Time elapsed: 4.2 mins\n",
      "Epoch: 100, Training loss: 876.0916, Training accuracy: 72.42%\n",
      "Total Training Time: 4.1838 mins\n"
     ]
    }
   ],
   "source": [
    "def calculate_loss(loss_func, outputs, targets):\n",
    "    total_loss = 0\n",
    "    for idx, key in enumerate(outputs):\n",
    "        output = outputs[key].to(device).double()\n",
    "        target = targets[:, idx].to(device).double()\n",
    "        total_loss += loss_func(output, target)\n",
    "    return total_loss\n",
    "\n",
    "def combine_and_threshold_predictions(class_predictions):\n",
    "    combined_tensor = [(class_predictions[label]) for label in class_predictions.keys()]\n",
    "    combined_tensor = torch.stack(combined_tensor).T\n",
    "    return combined_tensor.detach().cpu().apply_(lambda x: int(x > 0.5))\n",
    "\n",
    "def training_epoch(model, optimizer, loss_function, trainLoader):\n",
    "    epoch_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "    total_examples = 0\n",
    "\n",
    "    for tokens, targets in trainLoader:\n",
    "        tokens = tokens.to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        batch_size = tokens.shape[0]\n",
    "        total_examples += batch_size\n",
    "\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        class_predictions = model(tokens)\n",
    "        loss = calculate_loss(loss_function, class_predictions, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item() * batch_size\n",
    "\n",
    "        combined_predictions = combine_and_threshold_predictions(class_predictions)\n",
    "\n",
    "        correct_predictions += accuracy_score(combined_predictions.cpu().numpy(), targets.cpu().numpy())*batch_size\n",
    "    return epoch_loss, correct_predictions, total_examples\n",
    "\n",
    "epochs = 100\n",
    "\n",
    "startTime = time.time()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    loss, correct, total = training_epoch(model, optimizer, loss_function, trainLoader)\n",
    "        \n",
    "    if epoch % 5 == 0 or epoch == epochs - 1:\n",
    "            print(f'Time elapsed: {(time.time() - startTime) / 60:.1f} mins')\n",
    "            print(f'Epoch: {epoch + 1}, Training loss: {loss / total:.4f}, Training accuracy: {correct / total * 100:.2f}%')\n",
    "\n",
    "print(f'Total Training Time: {(time.time() - startTime) / 60:.4f} mins')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model size: 5.105MB\n"
     ]
    }
   ],
   "source": [
    "param_size = 0\n",
    "for param in model.parameters():\n",
    "    param_size += param.nelement() * param.element_size()\n",
    "buffer_size = 0\n",
    "for buffer in model.buffers():\n",
    "    buffer_size += buffer.nelement() * buffer.element_size()\n",
    "\n",
    "size_all_mb = (param_size + buffer_size) / 1024**2\n",
    "print('model size: {:.3f}MB'.format(size_all_mb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), './models/lstm.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "test = pd.read_csv('./processed-data/test.csv', converters={'TokensWithPadding': pd.eval})\n",
    "test.head()\n",
    "\n",
    "testingTokens = dataframeColumnToTensor(test['TokensWithPadding'])\n",
    "# Sanity check for tensors\n",
    "print(type(testingTokens))\n",
    "print(type(testingTokens[0]))\n",
    "\n",
    "testLoader = DataLoader(dataset=testingTokens, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractOneHotEncoding(prediction):\n",
    "    labelProbabilities = []\n",
    "    for label in prediction.keys():\n",
    "        labelProbabilities.append(int(prediction[label] > 0.5))\n",
    "    return [i for i, x in enumerate(labelProbabilities) if x == 1]\n",
    "\n",
    "model.eval()\n",
    "count = 0\n",
    "predictions = {}\n",
    "for tokens in testLoader:\n",
    "    # Move tokens to the same device as the model\n",
    "    tokens = tokens.to(device)\n",
    "    with torch.no_grad():\n",
    "        predictions[f'{count + 30000}.jpg'] = extractOneHotEncoding(model(tokens))\n",
    "    count+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classMapping(prediction):\n",
    "    if prediction == 0:\n",
    "      return 1\n",
    "    elif prediction == 1:\n",
    "      return 2\n",
    "    elif prediction == 2:\n",
    "      return 3\n",
    "    elif prediction == 3:\n",
    "      return 4\n",
    "    elif prediction == 4:\n",
    "      return 5\n",
    "    elif prediction == 5:\n",
    "      return 6\n",
    "    elif prediction == 6:\n",
    "      return 7\n",
    "    elif prediction == 7:\n",
    "      return 8\n",
    "    elif prediction == 8:\n",
    "      return 9\n",
    "    elif prediction == 9:\n",
    "      return 10\n",
    "    elif prediction == 10:\n",
    "      return 11\n",
    "    elif prediction == 11:\n",
    "      return 13\n",
    "    elif prediction == 12:\n",
    "      return 14\n",
    "    elif prediction == 13:\n",
    "      return 15\n",
    "    elif prediction == 14:\n",
    "      return 16\n",
    "    elif prediction == 15:\n",
    "      return 17\n",
    "    elif prediction == 16:\n",
    "      return 18\n",
    "    elif prediction == 17:\n",
    "      return 19\n",
    "    else:\n",
    "      return 0\n",
    "\n",
    "filepath = 'predictions/' + datetime.now().strftime(\"%d-%m-%Y-%H-%M\") + '-510369965-490424191-490299418.csv'\n",
    "\n",
    "with open(filepath, 'w', newline='') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerow(['ImageID', 'Labels'])\n",
    "    for key in predictions.keys():\n",
    "        row = []\n",
    "        for predictedClass in predictions[key]:\n",
    "            mapped = classMapping(predictedClass)\n",
    "            if mapped > 0:\n",
    "              row.append(mapped)\n",
    "        row = list(set(row))\n",
    "        writer.writerow([key, \" \".join(str(label) for label in row)])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NVIDIA GeForce RTX 3060 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(torch.cuda.get_device_name(0))\n",
    "# ^ Comment out if cpu :)\n",
    "\n",
    "import json\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import time\n",
    "import csv\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>ImageID</th>\n",
       "      <th>Labels</th>\n",
       "      <th>Caption</th>\n",
       "      <th>Tokens</th>\n",
       "      <th>LabelIds</th>\n",
       "      <th>EncodedLabels</th>\n",
       "      <th>DictionaryIds</th>\n",
       "      <th>TokensWithPadding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.jpg</td>\n",
       "      <td>[1]</td>\n",
       "      <td>Woman in swim suit holding parasol on sunny day.</td>\n",
       "      <td>['woman', 'swim', 'suit', 'holding', 'parasol'...</td>\n",
       "      <td>[0]</td>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[7236, 6376, 6297, 3077, 4457, 6316, 1714]</td>\n",
       "      <td>[7236, 6376, 6297, 3077, 4457, 6316, 1714, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.jpg</td>\n",
       "      <td>[1, 19]</td>\n",
       "      <td>A couple of men riding horses on top of a gree...</td>\n",
       "      <td>['couple', 'men', 'riding', 'horses', 'top', '...</td>\n",
       "      <td>[0, 17]</td>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[1524, 3891, 5237, 3117, 6650, 2827, 2351]</td>\n",
       "      <td>[1524, 3891, 5237, 3117, 6650, 2827, 2351, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2.jpg</td>\n",
       "      <td>[1]</td>\n",
       "      <td>They are brave for riding in the jungle on tho...</td>\n",
       "      <td>['brave', 'riding', 'jungle', 'eleph']</td>\n",
       "      <td>[0]</td>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[754, 5237, 3368, 2093]</td>\n",
       "      <td>[754, 5237, 3368, 2093, 0, 0, 0, 0, 0, 0, 0, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3.jpg</td>\n",
       "      <td>[8, 3, 13]</td>\n",
       "      <td>a black and silver clock tower at an intersect...</td>\n",
       "      <td>['black', 'silver', 'clock', 'tower', 'interse...</td>\n",
       "      <td>[7, 2, 11]</td>\n",
       "      <td>[0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, ...</td>\n",
       "      <td>[616, 5718, 1257, 6684, 3267, 4138, 6738]</td>\n",
       "      <td>[616, 5718, 1257, 6684, 3267, 4138, 6738, 0, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4.jpg</td>\n",
       "      <td>[8, 3, 7]</td>\n",
       "      <td>A train coming to a stop on the tracks out side.</td>\n",
       "      <td>['train', 'coming', 'stop', 'tracks', 'sid']</td>\n",
       "      <td>[7, 2, 6]</td>\n",
       "      <td>[0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, ...</td>\n",
       "      <td>[6704, 1367, 6178, 6694, 5677]</td>\n",
       "      <td>[6704, 1367, 6178, 6694, 5677, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 ImageID      Labels  \\\n",
       "0           0   0.jpg         [1]   \n",
       "1           1   1.jpg     [1, 19]   \n",
       "2           2   2.jpg         [1]   \n",
       "3           3   3.jpg  [8, 3, 13]   \n",
       "4           4   4.jpg   [8, 3, 7]   \n",
       "\n",
       "                                             Caption  \\\n",
       "0   Woman in swim suit holding parasol on sunny day.   \n",
       "1  A couple of men riding horses on top of a gree...   \n",
       "2  They are brave for riding in the jungle on tho...   \n",
       "3  a black and silver clock tower at an intersect...   \n",
       "4   A train coming to a stop on the tracks out side.   \n",
       "\n",
       "                                              Tokens    LabelIds  \\\n",
       "0  ['woman', 'swim', 'suit', 'holding', 'parasol'...         [0]   \n",
       "1  ['couple', 'men', 'riding', 'horses', 'top', '...     [0, 17]   \n",
       "2             ['brave', 'riding', 'jungle', 'eleph']         [0]   \n",
       "3  ['black', 'silver', 'clock', 'tower', 'interse...  [7, 2, 11]   \n",
       "4       ['train', 'coming', 'stop', 'tracks', 'sid']   [7, 2, 6]   \n",
       "\n",
       "                                       EncodedLabels  \\\n",
       "0  [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "1  [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "2  [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "3  [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, ...   \n",
       "4  [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, ...   \n",
       "\n",
       "                                DictionaryIds  \\\n",
       "0  [7236, 6376, 6297, 3077, 4457, 6316, 1714]   \n",
       "1  [1524, 3891, 5237, 3117, 6650, 2827, 2351]   \n",
       "2                     [754, 5237, 3368, 2093]   \n",
       "3   [616, 5718, 1257, 6684, 3267, 4138, 6738]   \n",
       "4              [6704, 1367, 6178, 6694, 5677]   \n",
       "\n",
       "                                   TokensWithPadding  \n",
       "0  [7236, 6376, 6297, 3077, 4457, 6316, 1714, 0, ...  \n",
       "1  [1524, 3891, 5237, 3117, 6650, 2827, 2351, 0, ...  \n",
       "2  [754, 5237, 3368, 2093, 0, 0, 0, 0, 0, 0, 0, 0...  \n",
       "3  [616, 5718, 1257, 6684, 3267, 4138, 6738, 0, 0...  \n",
       "4  [6704, 1367, 6178, 6694, 5677, 0, 0, 0, 0, 0, ...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The numpy arrays seem to have been converted to strings when saved to csv. We need to convert them back into lists\n",
    "\n",
    "train = pd.read_csv('./processed-data/train.csv', converters={'EncodedLabels': pd.eval, 'TokensWithPadding': pd.eval})\n",
    "train.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "# Mismatched storage :(\n",
    "print(type(train['EncodedLabels']))\n",
    "print(type(train['EncodedLabels'][0]))\n",
    "print(type(train['TokensWithPadding']))\n",
    "print(type(train['TokensWithPadding'][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make type consistent and convert to tensor\n",
    "def dataframeColumnToTensor(column):\n",
    "  array = []\n",
    "  for row in column:\n",
    "    array.append(row.tolist())\n",
    "  return torch.tensor(array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "trainingTokens = dataframeColumnToTensor(train['TokensWithPadding'])\n",
    "trainingEncodedLabels = dataframeColumnToTensor(train['EncodedLabels'])\n",
    "# Sanity check for tensors\n",
    "print(type(trainingTokens))\n",
    "print(type(trainingTokens[0]))\n",
    "print(type(trainingEncodedLabels))\n",
    "print(type(trainingEncodedLabels[0]))\n",
    "print(type(trainingEncodedLabels[0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split out validation set\n",
    "xTrain, xVal, yTrain, yVal = train_test_split(\n",
    "  trainingTokens,\n",
    "  trainingEncodedLabels,\n",
    "  test_size=0.15,\n",
    "  random_state=7\n",
    ")\n",
    "\n",
    "# Tokens\n",
    "print(xTrain.shape)\n",
    "print(xVal.shape)\n",
    "# Labels\n",
    "print(yTrain.shape)\n",
    "print(yVal.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Hyperparameter\n",
    "BATCH_SIZE=128\n",
    "\n",
    "trainData = TensorDataset(trainingTokens, trainingEncodedLabels)\n",
    "validationData = TensorDataset(xVal, yVal)\n",
    "\n",
    "trainLoader = DataLoader(dataset=trainData, batch_size=BATCH_SIZE, shuffle=True)\n",
    "validationLoader = DataLoader(dataset=validationData, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./processed-data/dictionary.json') as f:\n",
    "    dictionary = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "# Define classifier\n",
    "class LSTMClassifier(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, dictionary_size, num_labels, dropout_prob, bidirectional):\n",
    "        super(LSTMClassifier, self).__init__()\n",
    "        # MAx token length\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        # Vocabulary\n",
    "        self.dictionary_size = dictionary_size\n",
    "        self.num_labels = num_labels\n",
    "        self.dropout_prob = dropout_prob\n",
    "        self.bidirectional = bidirectional\n",
    "\n",
    "        self.word_embeddings = nn.Embedding(dictionary_size, input_size)\n",
    "\n",
    "        # Test with two lstms. num_layers=2\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, batch_first=True, bidirectional=bidirectional)\n",
    "\n",
    "        # Linear layer for each label\n",
    "        self.classifiers = nn.ModuleList([\n",
    "            nn.Sequential(\n",
    "                nn.Dropout(p=dropout_prob),\n",
    "                nn.Linear(in_features=hidden_size * (2 if bidirectional else 1), out_features=1)\n",
    "            ) for _ in range(num_labels)\n",
    "        ])\n",
    "\n",
    "    def forward(self, sentences):\n",
    "        # Create the word embeddings\n",
    "        embeds = self.word_embeddings(sentences)\n",
    "\n",
    "        # Pass it through the LSTM\n",
    "        lstm_out, _ = self.lstm(embeds)\n",
    "\n",
    "        # Get the last time step output for each label\n",
    "        if self.bidirectional:\n",
    "            lstm_out = torch.cat((lstm_out[:, -1, :self.hidden_size], lstm_out[:, 0, self.hidden_size:]), dim=1)\n",
    "        else:\n",
    "            lstm_out = lstm_out[:, -1, :]\n",
    "        \n",
    "        # Calculate the predictions for each label\n",
    "        outputs = {f'label{i+1}': torch.sigmoid(self.classifiers[i](lstm_out)).squeeze() for i in range(self.num_labels)}\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "INPUT_SIZE = 28\n",
    "HIDDEN_SIZE = 256\n",
    "DICTIONARY_SIZE = len(dictionary)\n",
    "LEARNING_RATE=0.001\n",
    "NUM_LABELS=18\n",
    "DROPOUT_RATE=0.5\n",
    "BIDIRECTIONAL=True\n",
    "\n",
    "# Initialize model, loss function, and optimizer\n",
    "model = LSTMClassifier(INPUT_SIZE, HIDDEN_SIZE, DICTIONARY_SIZE, NUM_LABELS, DROPOUT_RATE, BIDIRECTIONAL).to(device)\n",
    "\n",
    "# Load previous model for continued training\n",
    "# Caveat - the model structure can't be changed else the weight dimensions won't match\n",
    "# model.load_state_dict(torch.load('models/lstm_89per_600e_1lstm_50drop_bidirectional.pt'))\n",
    "# model.eval()\n",
    "\n",
    "loss_function = nn.CrossEntropyLoss().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed: 0.1 mins\n",
      "Epoch: 1, Training loss: 866.9306, Training accuracy: 85.46%\n",
      "Time elapsed: 0.3 mins\n",
      "Epoch: 6, Training loss: 866.6493, Training accuracy: 86.16%\n",
      "Time elapsed: 0.6 mins\n",
      "Epoch: 11, Training loss: 866.6069, Training accuracy: 86.81%\n",
      "Time elapsed: 0.8 mins\n",
      "Epoch: 16, Training loss: 866.5367, Training accuracy: 86.93%\n",
      "Time elapsed: 1.1 mins\n",
      "Epoch: 21, Training loss: 866.4456, Training accuracy: 87.15%\n",
      "Time elapsed: 1.4 mins\n",
      "Epoch: 26, Training loss: 866.5102, Training accuracy: 87.22%\n",
      "Time elapsed: 1.6 mins\n",
      "Epoch: 31, Training loss: 866.4626, Training accuracy: 87.51%\n",
      "Time elapsed: 1.9 mins\n",
      "Epoch: 36, Training loss: 866.5276, Training accuracy: 87.55%\n",
      "Time elapsed: 2.2 mins\n",
      "Epoch: 41, Training loss: 866.4223, Training accuracy: 87.50%\n",
      "Time elapsed: 2.5 mins\n",
      "Epoch: 46, Training loss: 866.3824, Training accuracy: 87.68%\n",
      "Time elapsed: 2.7 mins\n",
      "Epoch: 51, Training loss: 866.3660, Training accuracy: 87.79%\n",
      "Time elapsed: 3.0 mins\n",
      "Epoch: 56, Training loss: 866.2569, Training accuracy: 87.92%\n",
      "Time elapsed: 3.3 mins\n",
      "Epoch: 61, Training loss: 866.2057, Training accuracy: 88.08%\n",
      "Time elapsed: 3.5 mins\n",
      "Epoch: 66, Training loss: 866.3511, Training accuracy: 88.07%\n",
      "Time elapsed: 3.8 mins\n",
      "Epoch: 71, Training loss: 866.1911, Training accuracy: 88.01%\n",
      "Time elapsed: 4.1 mins\n",
      "Epoch: 76, Training loss: 866.1344, Training accuracy: 88.17%\n",
      "Time elapsed: 4.4 mins\n",
      "Epoch: 81, Training loss: 866.2740, Training accuracy: 88.23%\n",
      "Time elapsed: 4.7 mins\n",
      "Epoch: 86, Training loss: 866.1289, Training accuracy: 88.27%\n",
      "Time elapsed: 5.0 mins\n",
      "Epoch: 91, Training loss: 866.2571, Training accuracy: 88.29%\n",
      "Time elapsed: 5.3 mins\n",
      "Epoch: 96, Training loss: 866.1961, Training accuracy: 88.33%\n",
      "Time elapsed: 5.6 mins\n",
      "Epoch: 101, Training loss: 866.2000, Training accuracy: 88.33%\n",
      "Time elapsed: 6.0 mins\n",
      "Epoch: 106, Training loss: 866.0506, Training accuracy: 88.44%\n",
      "Time elapsed: 6.3 mins\n",
      "Epoch: 111, Training loss: 866.2671, Training accuracy: 88.47%\n",
      "Time elapsed: 6.6 mins\n",
      "Epoch: 116, Training loss: 866.3116, Training accuracy: 88.46%\n",
      "Time elapsed: 6.9 mins\n",
      "Epoch: 121, Training loss: 866.2435, Training accuracy: 88.52%\n",
      "Time elapsed: 7.3 mins\n",
      "Epoch: 126, Training loss: 866.2173, Training accuracy: 88.44%\n",
      "Time elapsed: 7.6 mins\n",
      "Epoch: 131, Training loss: 866.2731, Training accuracy: 88.51%\n",
      "Time elapsed: 7.9 mins\n",
      "Epoch: 136, Training loss: 866.1035, Training accuracy: 88.49%\n",
      "Time elapsed: 8.2 mins\n",
      "Epoch: 141, Training loss: 866.2182, Training accuracy: 88.50%\n",
      "Time elapsed: 8.5 mins\n",
      "Epoch: 146, Training loss: 866.2855, Training accuracy: 88.68%\n",
      "Time elapsed: 8.9 mins\n",
      "Epoch: 151, Training loss: 866.1996, Training accuracy: 88.65%\n",
      "Time elapsed: 9.2 mins\n",
      "Epoch: 156, Training loss: 866.0894, Training accuracy: 88.49%\n",
      "Time elapsed: 9.5 mins\n",
      "Epoch: 161, Training loss: 866.1239, Training accuracy: 88.73%\n",
      "Time elapsed: 9.9 mins\n",
      "Epoch: 166, Training loss: 866.0382, Training accuracy: 88.73%\n",
      "Time elapsed: 10.2 mins\n",
      "Epoch: 171, Training loss: 866.1351, Training accuracy: 88.72%\n",
      "Time elapsed: 10.5 mins\n",
      "Epoch: 176, Training loss: 865.9574, Training accuracy: 88.81%\n",
      "Time elapsed: 10.8 mins\n",
      "Epoch: 181, Training loss: 866.1540, Training accuracy: 88.83%\n",
      "Time elapsed: 11.1 mins\n",
      "Epoch: 186, Training loss: 866.0879, Training accuracy: 88.79%\n",
      "Time elapsed: 11.5 mins\n",
      "Epoch: 191, Training loss: 865.9750, Training accuracy: 88.85%\n",
      "Time elapsed: 11.8 mins\n",
      "Epoch: 196, Training loss: 866.0304, Training accuracy: 88.66%\n",
      "Time elapsed: 12.1 mins\n",
      "Epoch: 201, Training loss: 866.0150, Training accuracy: 88.87%\n",
      "Time elapsed: 12.4 mins\n",
      "Epoch: 206, Training loss: 866.0894, Training accuracy: 88.84%\n",
      "Time elapsed: 12.7 mins\n",
      "Epoch: 211, Training loss: 866.1124, Training accuracy: 88.86%\n",
      "Time elapsed: 13.0 mins\n",
      "Epoch: 216, Training loss: 866.0502, Training accuracy: 88.88%\n",
      "Time elapsed: 13.4 mins\n",
      "Epoch: 221, Training loss: 865.9691, Training accuracy: 88.83%\n",
      "Time elapsed: 13.7 mins\n",
      "Epoch: 226, Training loss: 865.9081, Training accuracy: 88.95%\n",
      "Time elapsed: 14.0 mins\n",
      "Epoch: 231, Training loss: 866.0967, Training accuracy: 88.92%\n",
      "Time elapsed: 14.4 mins\n",
      "Epoch: 236, Training loss: 866.0921, Training accuracy: 88.94%\n",
      "Time elapsed: 14.7 mins\n",
      "Epoch: 241, Training loss: 866.0480, Training accuracy: 88.94%\n",
      "Time elapsed: 15.0 mins\n",
      "Epoch: 246, Training loss: 865.9495, Training accuracy: 88.99%\n",
      "Time elapsed: 15.3 mins\n",
      "Epoch: 251, Training loss: 866.1513, Training accuracy: 89.07%\n",
      "Time elapsed: 15.6 mins\n",
      "Epoch: 256, Training loss: 866.0025, Training accuracy: 89.11%\n",
      "Time elapsed: 16.0 mins\n",
      "Epoch: 261, Training loss: 865.8864, Training accuracy: 88.96%\n",
      "Time elapsed: 16.3 mins\n",
      "Epoch: 266, Training loss: 865.9436, Training accuracy: 88.99%\n",
      "Time elapsed: 16.6 mins\n",
      "Epoch: 271, Training loss: 865.9821, Training accuracy: 89.00%\n",
      "Time elapsed: 16.9 mins\n",
      "Epoch: 276, Training loss: 865.8447, Training accuracy: 89.04%\n",
      "Time elapsed: 17.2 mins\n",
      "Epoch: 281, Training loss: 866.0967, Training accuracy: 88.95%\n",
      "Time elapsed: 17.5 mins\n",
      "Epoch: 286, Training loss: 865.8317, Training accuracy: 89.06%\n",
      "Time elapsed: 17.8 mins\n",
      "Epoch: 291, Training loss: 865.9863, Training accuracy: 89.11%\n",
      "Time elapsed: 18.2 mins\n",
      "Epoch: 296, Training loss: 865.8936, Training accuracy: 89.09%\n",
      "Time elapsed: 18.4 mins\n",
      "Epoch: 300, Training loss: 865.9241, Training accuracy: 89.11%\n",
      "Total Training Time: 18.4389 mins\n"
     ]
    }
   ],
   "source": [
    "def calculate_loss(loss_func, outputs, targets):\n",
    "    total_loss = 0\n",
    "    for idx, key in enumerate(outputs):\n",
    "        output = outputs[key].to(device).double()\n",
    "        target = targets[:, idx].to(device).double()\n",
    "        total_loss += loss_func(output, target)\n",
    "    return total_loss\n",
    "\n",
    "# Take all the batched predictions and get individual labels\n",
    "def combine_and_threshold_predictions(class_predictions):\n",
    "    combined_tensor = [(class_predictions[label]) for label in class_predictions.keys()]\n",
    "    combined_tensor = torch.stack(combined_tensor).T\n",
    "    return combined_tensor.detach().cpu().apply_(lambda x: int(x > 0.5))\n",
    "\n",
    "def training_epoch(model, optimizer, loss_function, trainLoader):\n",
    "    epoch_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "    total_examples = 0\n",
    "\n",
    "    for tokens, targets in trainLoader:\n",
    "        tokens = tokens.to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        batch_size = tokens.shape[0]\n",
    "        total_examples += batch_size\n",
    "\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        class_predictions = model(tokens)\n",
    "        loss = calculate_loss(loss_function, class_predictions, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item() * batch_size\n",
    "\n",
    "        combined_predictions = combine_and_threshold_predictions(class_predictions)\n",
    "\n",
    "        correct_predictions += accuracy_score(combined_predictions.cpu().numpy(), targets.cpu().numpy())*batch_size\n",
    "    return epoch_loss, correct_predictions, total_examples\n",
    "\n",
    "epochs = 300\n",
    "\n",
    "startTime = time.time()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    loss, correct, total = training_epoch(model, optimizer, loss_function, trainLoader)\n",
    "        \n",
    "    if epoch % 5 == 0 or epoch == epochs - 1:\n",
    "            print(f'Time elapsed: {(time.time() - startTime) / 60:.1f} mins')\n",
    "            print(f'Epoch: {epoch + 1}, Training loss: {loss / total:.4f}, Training accuracy: {correct / total * 100:.2f}%')\n",
    "\n",
    "print(f'Total Training Time: {(time.time() - startTime) / 60:.4f} mins')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model size: 6.630MB\n"
     ]
    }
   ],
   "source": [
    "param_size = 0\n",
    "for param in model.parameters():\n",
    "    param_size += param.nelement() * param.element_size()\n",
    "buffer_size = 0\n",
    "for buffer in model.buffers():\n",
    "    buffer_size += buffer.nelement() * buffer.element_size()\n",
    "\n",
    "size_all_mb = (param_size + buffer_size) / 1024**2\n",
    "print('model size: {:.3f}MB'.format(size_all_mb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), './models/lstm.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "test = pd.read_csv('./processed-data/test.csv', converters={'TokensWithPadding': pd.eval})\n",
    "test.head()\n",
    "\n",
    "testingTokens = dataframeColumnToTensor(test['TokensWithPadding'])\n",
    "# Sanity check for tensors\n",
    "print(type(testingTokens))\n",
    "print(type(testingTokens[0]))\n",
    "\n",
    "testLoader = DataLoader(dataset=testingTokens, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predictions in usable format\n",
    "def extractOneHotEncoding(prediction):\n",
    "    labelProbabilities = []\n",
    "    rawPrediction = []\n",
    "    for label in prediction.keys():\n",
    "        newPrediction = prediction[label]\n",
    "        labelProbabilities.append(int(newPrediction > 0.5))\n",
    "        rawPrediction.append(float(newPrediction))\n",
    "    return [i for i, x in enumerate(labelProbabilities) if x == 1], rawPrediction\n",
    "\n",
    "model.eval()\n",
    "count = 0\n",
    "predictions = {}\n",
    "rawPredictions = []\n",
    "for tokens in testLoader:\n",
    "    # Move tokens to the same device as the model\n",
    "    tokens = tokens.to(device)\n",
    "    with torch.no_grad():\n",
    "        oneHot, rawPrediction = extractOneHotEncoding(model(tokens))\n",
    "        predictions[f'{count + 30000}.jpg'] = oneHot\n",
    "        rawPredictions.append(rawPrediction)\n",
    "    count+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cater for the missing class 12\n",
    "def classMapping(prediction):\n",
    "    if prediction == 0:\n",
    "      return 1\n",
    "    elif prediction == 1:\n",
    "      return 2\n",
    "    elif prediction == 2:\n",
    "      return 3\n",
    "    elif prediction == 3:\n",
    "      return 4\n",
    "    elif prediction == 4:\n",
    "      return 5\n",
    "    elif prediction == 5:\n",
    "      return 6\n",
    "    elif prediction == 6:\n",
    "      return 7\n",
    "    elif prediction == 7:\n",
    "      return 8\n",
    "    elif prediction == 8:\n",
    "      return 9\n",
    "    elif prediction == 9:\n",
    "      return 10\n",
    "    elif prediction == 10:\n",
    "      return 11\n",
    "    elif prediction == 11:\n",
    "      return 13\n",
    "    elif prediction == 12:\n",
    "      return 14\n",
    "    elif prediction == 13:\n",
    "      return 15\n",
    "    elif prediction == 14:\n",
    "      return 16\n",
    "    elif prediction == 15:\n",
    "      return 17\n",
    "    elif prediction == 16:\n",
    "      return 18\n",
    "    elif prediction == 17:\n",
    "      return 19\n",
    "    else:\n",
    "      return 0\n",
    "\n",
    "filepath = 'predictions/' + datetime.now().strftime(\"%d-%m-%Y-%H-%M\") + '-510369965-490424191-490299418.csv'\n",
    "\n",
    "with open(filepath, 'w', newline='') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerow(['ImageID', 'Labels'])\n",
    "    for key in predictions.keys():\n",
    "        row = []\n",
    "        for predictedClass in predictions[key]:\n",
    "            mapped = classMapping(predictedClass)\n",
    "            if mapped > 0:\n",
    "              row.append(mapped)\n",
    "        row = list(set(row))\n",
    "        writer.writerow([key, \" \".join(str(label) for label in row)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# raw predictions are used for the ensemble\n",
    "with open('./processed-data/rawPredictions-lstm.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(rawPredictions, f, ensure_ascii=False, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
